import json
import os
import re
import time
import concurrent.futures
from functools import partial
from zhipuai import ZhipuAI

class Colors:
    GREEN = '\033[92m'
    YELLOW = '\033[93m'
    RED = '\033[91m'
    BLUE = '\033[94m'
    END = '\033[0m'

class CotValidator:
    @staticmethod
    def validate(answer):
        """å¢å¼ºçš„CoTæ ¼å¼éªŒè¯"""
        # æ£€æŸ¥æ ‡ç­¾å®Œæ•´æ€§
        think_blocks = re.findall(r'<think>(.*?)</think>', answer, re.DOTALL)
        if not think_blocks:
            raise ValueError("å¿…é¡»åŒ…å«<think>æ€è€ƒæ ‡ç­¾")
        if len(re.findall(r'<think>', answer)) != len(re.findall(r'</think>', answer)):
            raise ValueError("æ€è€ƒæ ‡ç­¾ä¸åŒ¹é…")
        
        # éªŒè¯æ€è€ƒå†…å®¹è´¨é‡
        for think in think_blocks:
            if len(think.strip()) < 50:
                raise ValueError("æ€è€ƒå†…å®¹è¿‡çŸ­ï¼ˆè‡³å°‘50å­—ç¬¦ï¼‰")
            if not re.search(r'[ï¼Œã€‚ï¼Ÿï¼šï¼›]', think):  # æ£€æŸ¥æ˜¯å¦æœ‰å¤šå¥å¼åˆ†æ
                raise ValueError("æ€è€ƒå†…å®¹éœ€åŒ…å«å®Œæ•´åˆ†æè¿‡ç¨‹")
        
        # éªŒè¯å®é™…å›ç­”ä¸æ€è€ƒçš„å…³è”æ€§
        clean_answer = re.sub(r'<think>.*?</think>', '', answer, flags=re.DOTALL).strip()
        if not clean_answer:
            raise ValueError("å®é™…å›ç­”ä¸èƒ½ä¸ºç©º")
        if len(clean_answer) < len(think_blocks[0])/3:
            raise ValueError("å®é™…å›ç­”å†…å®¹è¿‡ç®€")
        return True

def load_questions(py_path):
    """ä»Pythonæ–‡ä»¶åŠ è½½é—®é¢˜åˆ—è¡¨"""
    try:
        with open(py_path, "r", encoding="utf-8") as f:
            namespace = {}
            exec(f.read(), namespace)
            return namespace.get("questions", [])
    except Exception as e:
        raise RuntimeError(f"è§£æé—®é¢˜æ–‡ä»¶å¤±è´¥: {str(e)}")

def load_existing_data(json_path):
    """åŠ è½½å·²æœ‰æ•°æ®å¹¶å»ºç«‹é—®é¢˜ç´¢å¼•"""
    processed = set()
    if os.path.exists(json_path):
        try:
            with open(json_path, "r", encoding="utf-8") as f:
                data = json.load(f)
                for entry in data:
                    processed.add(entry["instruction"].strip())
            print(f"{Colors.GREEN}âœ… å·²åŠ è½½{len(processed)}æ¡å·²å¤„ç†æ•°æ®{Colors.END}")
        except Exception as e:
            os.rename(json_path, f"{json_path}.bak")
            print(f"{Colors.YELLOW}âš  æ•°æ®æ–‡ä»¶æŸåï¼Œå·²å¤‡ä»½: {str(e)}{Colors.END}")
    return processed

def generate_deepseek_entry(question, answer):
    """å¢å¼ºæ•°æ®æ ¼å¼ç”Ÿæˆ"""
    return {
        "instruction": f"{question}\nè¯·é€æ­¥æ€è€ƒå¹¶ç»™å‡ºä¸“ä¸šè§£ç­”",
        "input": "",
        "output": f"{answer}\n\n<å®‰å…¨æç¤º>è¯·åœ¨å®é™…æ“ä½œä¸­ä¸¥æ ¼éµå®ˆå®‰å…¨è§„èŒƒï¼Œå¿…è¦æ—¶å’¨è¯¢ä¸“ä¸šå·¥ç¨‹å¸ˆ</æç¤º>"
    }

def save_with_backup(data, path):
    """å¸¦å¤‡ä»½çš„å®‰å…¨ä¿å­˜ï¼ˆJSONæ•°ç»„æ ¼å¼ï¼‰"""
    temp_path = f"{path}.tmp"
    try:
        # è¯»å–ç°æœ‰æ•°æ®
        existing = []
        if os.path.exists(path):
            with open(path, "r", encoding="utf-8") as f:
                existing = json.load(f)

        # åˆå¹¶æ•°æ®
        combined = existing + data

        # å†™å…¥ä¸´æ—¶æ–‡ä»¶
        with open(temp_path, "w", encoding="utf-8") as f:
            json.dump(combined, f, ensure_ascii=False, indent=2)

        # åŸå­æ›¿æ¢
        if os.path.exists(path):
            os.replace(path, f"{path}.bak")
        os.rename(temp_path, path)
    except Exception as e:
        print(f"{Colors.RED}ä¿å­˜å¤±è´¥: {str(e)}{Colors.END}")
        if os.path.exists(temp_path):
            os.remove(temp_path)

def process_question(client, system_prompt, question, error_log, retry=3):
    """æ”¹è¿›çš„æ€è€ƒé“¾ç”Ÿæˆé€»è¾‘"""
    for attempt in range(retry):
        try:
            # å¢å¼ºæç¤ºå·¥ç¨‹
            user_prompt = f"{question}\nè¯·æŒ‰ä»¥ä¸‹æ­¥éª¤å›ç­”ï¼š\n1. è¯¦ç»†åˆ†æé—®é¢˜èƒŒæ™¯\n2. è€ƒè™‘å¤šç§å¯èƒ½æ€§\n3. ç»™å‡ºåˆ†æ­¥è§£å†³æ–¹æ¡ˆ\n4. æ€»ç»“æ³¨æ„äº‹é¡¹"
            
            response = client.chat.completions.create(
                model="glm-4-flash",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.5,  # æé«˜åˆ›é€ æ€§
                max_tokens=2500
            )
            answer = response.choices[0].message.content
            
            # å¢å¼ºæ ¼å¼å¤„ç†
            answer = re.sub(r'(?i)<think>', '<think>', answer)
            answer = re.sub(r'(?i)</think>', '</think>', answer)
            answer = re.sub(r'ï¼ˆ([^ï¼‰]+)ï¼‰', r'ï¼ˆ\1ï¼‰', answer)  # ç»Ÿä¸€æ‹¬å·
            
            # å¢åŠ äºŒæ¬¡æ€è€ƒéªŒè¯
            if answer.count('<think>') < 1:
                answer = f"<think>é—®é¢˜åˆ†æï¼š\n{answer.split('</think>')[0] if '</think>' in answer else answer}</think>\n{answer}"
                
            CotValidator.validate(answer)
            return generate_deepseek_entry(question, answer)
            
        except Exception as e:
            if attempt < retry - 1:
                wait_time = 2 ** (attempt + 1)
                print(f"{Colors.YELLOW}âš  ç¬¬{attempt+1}æ¬¡é‡è¯•ï¼Œç­‰å¾…{wait_time}ç§’...{Colors.END}")
                time.sleep(wait_time)
            else:
                # æ ¼å¼åŒ–é”™è¯¯è®°å½•
                error_msg = str(e)
                timestamp = time.strftime("%Y-%m-%d %H:%M:%S")
                with open(error_log, "a", encoding="utf-8") as f:
                    f.write(f"[{timestamp}] é—®é¢˜: {question}\né”™è¯¯: {error_msg}\n{'='*50}\n")
                return None

def process_question_wrapper(client, system_prompt, error_log, question):
    """å¢åŠ è¿›åº¦æç¤º"""
    try:
        print(f"{Colors.BLUE}ğŸŸ¡ å¤„ç†ä¸­: {question[:35]}...{Colors.END}")
        start_time = time.time()
        result = process_question(client, system_prompt, question, error_log)
        elapsed = time.time() - start_time
        
        if result:
            think_len = len(re.search(r'<think>(.*?)</think>', result['output'], re.DOTALL).group(1))
            ans_len = len(result['output']) - think_len
            print(f"{Colors.GREEN}âœ… æˆåŠŸ | è€—æ—¶:{elapsed:.1f}s | æ€è€ƒ:{think_len}å­— | å›ç­”:{ans_len}å­—{Colors.END}")
            return result
        else:
            print(f"{Colors.YELLOW}âš ï¸ ç©ºå“åº”: {question[:30]}...{Colors.END}")
        return None
    except Exception as e:
        print(f"{Colors.RED}âŒ å¤±è´¥: {str(e)[:50]}...{Colors.END}")
        return None

def process_batch(client, system_prompt, error_log, batch):
    """å¸¦ç»Ÿè®¡çš„æ‰¹æ¬¡å¤„ç†"""
    print(f"\n{Colors.BLUE}â–¶ å¼€å§‹æ‰¹æ¬¡å¤„ç† ({len(batch)}ä¸ªé—®é¢˜) {Colors.END}")
    with concurrent.futures.ThreadPoolExecutor(max_workers=100) as executor:
        process_fn = partial(process_question_wrapper, client, system_prompt, error_log)
        results = list(executor.map(process_fn, batch))

    success = sum(1 for r in results if r)
    failed = len(results) - success
    print(f"{Colors.GREEN}âœ” æˆåŠŸ: {success} {Colors.YELLOW}âš  å¤±è´¥: {failed}{Colors.END}")
    return [r for r in results if r]

def save_progress(processed_questions, progress_file):
    """ä¿å­˜å¤„ç†è¿›åº¦"""
    try:
        with open(progress_file, "w", encoding="utf-8") as f:
            json.dump(list(processed_questions), f, ensure_ascii=False)
    except Exception as e:
        print(f"{Colors.RED}âŒ ä¿å­˜è¿›åº¦å¤±è´¥: {str(e)}{Colors.END}")

def load_progress(progress_file):
    """åŠ è½½å¤„ç†è¿›åº¦"""
    processed = set()
    if os.path.exists(progress_file):
        try:
            with open(progress_file, "r", encoding="utf-8") as f:
                processed = set(json.load(f))
            print(f"{Colors.GREEN}âœ… å·²åŠ è½½{len(processed)}æ¡è¿›åº¦æ•°æ®{Colors.END}")
        except Exception as e:
            print(f"{Colors.YELLOW}âš  åŠ è½½è¿›åº¦å¤±è´¥: {str(e)}{Colors.END}")
    return processed

def main():
    client = ZhipuAI(api_key="4e0779dc66414dc4afe0872680957d40.HnKsmRuaJjYQHEUL")
    
    # ä¿®æ”¹åçš„ç³»ç»Ÿæç¤ºï¼ˆå…³é”®æ”¹è¿›ï¼‰
    system_prompt = """
ä½œä¸ºèµ„æ·±åŒ–å·¥å®‰å…¨ä¸“å®¶ï¼Œè¯·ä¸¥æ ¼æŒ‰ä»¥ä¸‹æ ¼å¼å›ç­”ï¼š

<think>
ã€é—®é¢˜åˆ†æã€‘
1. è¯†åˆ«æ ¸å¿ƒå®‰å…¨é£é™©ï¼ˆè‡³å°‘3ä¸ªæ–¹é¢ï¼‰
2. åˆ—ä¸¾ç›¸å…³æ³•è§„æ ‡å‡†ï¼ˆGB/Tã€AQç­‰ï¼‰
3. è€ƒè™‘ä¸åŒåœºæ™¯ä¸‹çš„åº”å¯¹æ–¹æ¡ˆ
4. è¯„ä¼°å¸¸è§è¯¯æ“ä½œåŠå…¶åæœ

ã€è§£å†³æ€è·¯ã€‘
- åˆ†æ­¥éª¤å±•å¼€è§£å†³æ–¹æ¡ˆ
- æ¯”è¾ƒä¸åŒæ–¹æ³•çš„ä¼˜ç¼ºç‚¹
- ç»“åˆæœ€æ–°è¡Œä¸šæ¡ˆä¾‹
- ç‰¹æ®Šæƒ…å†µçš„åº”æ€¥å¤„ç†
</think>

ã€ä¸“ä¸šå›ç­”ã€‘
æŒ‰æ­¤ç»“æ„å‘ˆç°ï¼š
1. ç«‹å³è¡ŒåŠ¨æ–¹æ¡ˆï¼ˆå¸¦ç¼–å·æ­¥éª¤ï¼‰
2. æ ¹æœ¬åŸå› æ’æŸ¥ï¼ˆæ£€æŸ¥æ¸…å•ï¼‰
3. é•¿æœŸé¢„é˜²æªæ–½
4. åŸ¹è®­å»ºè®®

ç¤ºä¾‹ï¼š
é—®é¢˜ï¼šååº”é‡œå‹åŠ›å¼‚å¸¸å‡é«˜å¦‚ä½•å¤„ç†ï¼Ÿ

<think>
ã€é—®é¢˜åˆ†æã€‘
1. å®‰å…¨é£é™©ï¼šè¶…å‹çˆ†ç‚¸ã€ç‰©æ–™æ³„æ¼ã€è¿é”ååº”å¤±æ§
2. ç›¸å…³æ ‡å‡†ï¼šGB/T 21109ã€AQ/T 3034
3. å¯èƒ½åŸå› ï¼šå†·å´å¤±æ•ˆã€è¿›æ–™è¿‡é‡ã€æ…æ‹Œæ•…éšœã€ä»ªè¡¨è¯¯æŠ¥
4. è¯¯æ“ä½œåæœï¼šé”™è¯¯æ³„å‹å¯¼è‡´æ¯’æ°”é‡Šæ”¾ã€ç›²ç›®æ£€ä¿®å¼•å‘ç«èŠ±

ã€è§£å†³æ€è·¯ã€‘
- ä¼˜å…ˆä¿éšœäººå‘˜å®‰å…¨ï¼Œå¯åŠ¨è‡ªåŠ¨è”é”
- åŒºåˆ†ç‰©ç†æ€§è¶…å‹ä¸ååº”æ€§è¶…å‹
- è€ƒè™‘å¤œé—´å€¼ç­äººå‘˜çš„å¤„ç½®èƒ½åŠ›
- å‚è€ƒ2022å¹´æŸåŒ–å·¥å‚åŒç±»äº‹æ•…å¤„ç†æŠ¥å‘Š
</think>

ã€ä¸“ä¸šå›ç­”ã€‘
1. ç´§æ€¥å¤„ç½®ï¼š
   (1) ç«‹å³å¯åŠ¨E-101ç´§æ€¥æ³„å‹é˜€
   (2) åˆ‡æ–­è¿›æ–™æ³µP-203
   (3) å¼€å¯å¤‡ç”¨å†·å´æ°´ç³»ç»Ÿ

2. æ’æŸ¥æ¸…å•ï¼š
   âˆš æ£€æŸ¥TICA-307æ¸©åº¦è®°å½•æ›²çº¿
   âˆš ç¡®è®¤æ…æ‹Œå™¨M-102ç”µæµæ³¢åŠ¨
   âˆš æ ¡å‡†PRC-208å‹åŠ›ä¼ æ„Ÿå™¨

3. é¢„é˜²æªæ–½ï¼š
   - æ¯æœˆè¿›è¡Œæ³„å‹é˜€æ‰‹åŠ¨æµ‹è¯•
   - å®‰è£…å‹å·®æŠ¥è­¦è£…ç½®ï¼ˆâ‰¤0.3MPaï¼‰

4. åŸ¹è®­é‡ç‚¹ï¼š
   * å¤œé—´åº”æ€¥å¤„ç½®æ¼”ç»ƒ
   * å¤šå·¥å†µå‹åŠ›è¯†åˆ«åŸ¹è®­
"""

    # æ–‡ä»¶é…ç½®
    base_dir = os.path.dirname(os.path.abspath(__file__))
    question_file = os.path.join(base_dir, "extracted_5000_questions.py")
    output_file = os.path.join(base_dir, "chemical_safety_deepseek_3.json")
    error_log = os.path.join(base_dir, "deepseek_errors.log")
    progress_file = os.path.join(base_dir, "progress.json")

    # æ£€æŸ¥æ˜¯å¦éœ€è¦æ¸…ç†é”™è¯¯æ—¥å¿—
    if os.path.exists(error_log) and os.path.getsize(error_log) > 0:
        # åˆ›å»ºå¤‡ä»½
        backup_error_log = f"{error_log}.{time.strftime('%Y%m%d%H%M%S')}.bak"
        os.rename(error_log, backup_error_log)
        print(f"{Colors.YELLOW}âš  å·²å¤‡ä»½æ—§é”™è¯¯æ—¥å¿—åˆ° {backup_error_log}{Colors.END}")
        # åˆ›å»ºæ–°çš„ç©ºæ—¥å¿—æ–‡ä»¶
        with open(error_log, "w", encoding="utf-8") as f:
            f.write(f"# é”™è¯¯æ—¥å¿— - åˆ›å»ºäº {time.strftime('%Y-%m-%d %H:%M:%S')}\n\n")

    # åŠ è½½æ•°æ®
    processed = load_existing_data(output_file)
    progress = load_progress(progress_file)
    processed.update(progress)  # åˆå¹¶å·²å¤„ç†çš„é—®é¢˜
    
    all_questions = load_questions(question_file)
    todo_questions = [q for q in all_questions if q not in processed]
    
    print(f"{Colors.BLUE}ğŸ“Š å¾…å¤„ç†é—®é¢˜ï¼š{len(todo_questions)}/{len(all_questions)}{Colors.END}")
    
    if not todo_questions:
        print(f"{Colors.GREEN}âœ… æ‰€æœ‰é—®é¢˜å·²å¤„ç†å®Œæˆ{Colors.END}")
        return

    # åˆ†æ‰¹å¤„ç†
    batch_size = 200
    for idx in range(0, len(todo_questions), batch_size):
        batch = todo_questions[idx:idx+batch_size]
        print(f"\n{Colors.BLUE}ğŸ”· å¤„ç†æ‰¹æ¬¡ {idx//batch_size + 1} [æ•°é‡ï¼š{len(batch)}]{Colors.END}")
        
        results = process_batch(client, system_prompt, error_log, batch)
        
        if results:
            save_with_backup(results, output_file)
            # æ›´æ–°è¿›åº¦
            processed.update(batch)
            save_progress(processed, progress_file)
            print(f"{Colors.GREEN}âœ… å·²ä¿å­˜{len(results)}æ¡æ•°æ®{Colors.END}")
            
            # æ‰“å°è¿›åº¦
            progress = len(processed) / len(all_questions) * 100
            print(f"{Colors.BLUE}ğŸ“ˆ æ€»è¿›åº¦: {progress:.1f}%{Colors.END}")

if __name__ == "__main__":
    main()